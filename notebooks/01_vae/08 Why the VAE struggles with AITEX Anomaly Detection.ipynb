{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17bdd2ad",
   "metadata": {},
   "source": [
    "# **Project: Anomaly Detection for AITEX Dataset**\n",
    "#### Track: VAE\n",
    "## `Notebook 8`: Why the VAE Approach Struggles with AITEX Anomaly Detection\n",
    "**Author**: Oliver Grau \n",
    "\n",
    "**Date**: 27.03.2025  \n",
    "**Version**: 1.0\n",
    "\n",
    "## üìö Table of Contents\n",
    "\n",
    "- [Why the VAE Approach Struggles with AITEX Anomaly Detection](#why-the-vae-approach-struggles-with-aitex-anomaly-detection)\n",
    "  - [1. Introduction](#1-introduction)\n",
    "  - [2. What We Tried: Architectural Experiments](#2-what-we-tried-architectural-experiments)\n",
    "    - [Original VAE Architecture](#original-vae-architecture)\n",
    "    - [Introducing Skip Connections](#introducing-skip-connections)\n",
    "    - [Attention Blocks (SEBlocks)](#attention-blocks-seblocks)\n",
    "    - [Gated Skip Connections](#gated-skip-connections)\n",
    "  - [3. Observations from Experiments](#3-observations-from-experiments)\n",
    "    - [Interpreting Our Observations: Why Did the VAE Struggle?](#interpreting-our-observations-why-did-the-vae-struggle)\n",
    "    - [Why Thresholding Error Maps Isn‚Äôt Enough](#why-thresholding-error-maps-isnt-enough)\n",
    "    - [How VAEs Respond to Different Anomaly Types](#how-vaes-respond-to-different-anomaly-types)\n",
    "      - [Behavior Summary](#-behavior-summary)\n",
    "      - [Why does this happen?](#why-does-this-happen)\n",
    "      - [Takeaway for Learners](#takeaway-for-learners)\n",
    "  - [3. What Did We Learn from This?](#Ô∏è-3-what-did-we-learn-from-this)\n",
    "    - [Next Steps: Beyond VAE](#-next-steps-beyond-vae)\n",
    "    - [Conclusion for Learners](#-conclusion-for-learners)\n",
    "      - [Final thought](#-final-thought)\n",
    "    - [Final Reflection: Why VAEs Aren‚Äôt Enough for AITEX](#final-reflection-why-vaes-arent-enough-for-aitex)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this notebook, we summarize the exploratory process and key findings from using **Variational Autoencoders (VAEs)** for anomaly detection on the **AITEX fabric dataset**. \n",
    "\n",
    "You‚Äôll see clearly why a simple **reconstruction-based VAE approach** faces difficulties, despite several attempts to improve it through architectural enhancements like skip connections, attention blocks, and gated skip connections.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. What We Tried: Architectural Experiments\n",
    "\n",
    "Throughout our experiments, we explored multiple ways to make the VAE reconstruction more accurate and more sensitive to anomalies. Here‚Äôs what we tested in detail:\n",
    "\n",
    "### **1. Original VAE Architecture**\n",
    "- A basic Convolutional VAE trained only on **normal (defect-free)** fabric images.\n",
    "- Goal: **Detect anomalies by reconstruction error** (high error ‚Üí anomaly).\n",
    "\n",
    "### **2. Introducing Skip Connections**\n",
    "We tried two types of skip connections to enhance reconstruction:\n",
    "- **Additive Skip Connections** (directly adding encoder features to the decoder).\n",
    "- **Concatenative Skip Connections** (concatenating encoder features to decoder features, followed by convolutional fusion).\n",
    "\n",
    "**Why we did this:**  \n",
    "We wanted better reconstruction quality so anomalies would stand out more sharply in the error map.\n",
    "\n",
    "### **3. Attention Blocks (SEBlocks)**\n",
    "We integrated **Squeeze-and-Excitation (SE) blocks** to dynamically recalibrate feature channels at the latent bottleneck, helping the network to decide which features were important.\n",
    "\n",
    "**Motivation:**  \n",
    "To see if attention could help the VAE reconstruct normal textures well, yet struggle to reconstruct anomalies, thus highlighting them clearly.\n",
    "\n",
    "### **4. Gated Skip Connections**\n",
    "We finally tested **ChannelGate**, a learned gating mechanism applied to skip connections, giving the model control over how much encoder information should flow into the decoder.\n",
    "\n",
    "**Reasoning:**  \n",
    "We hypothesized gating could help suppress the reconstruction of anomalous details carried through skip connections.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Observations from Experiments\n",
    "\n",
    "During multiple training sessions and thorough evaluations, we observed several consistent behaviors in the VAE approach:\n",
    "\n",
    "**1. Bright Anomalies (White spots):**  \n",
    "- Clearly reconstructed incorrectly (turned darker), resulting in high reconstruction error.\n",
    "- ‚úÖ **Good anomaly detection**.\n",
    "\n",
    "![Bright anomaly example](images/white_anomaly.png)\n",
    "\n",
    "---\n",
    "\n",
    "**2. Dark Anomalies (Black fissures, texture disruptions):**  \n",
    "- Reconstructed inversely (turned brighter/whitish), thus reducing pixel-wise error, or even causing inversion in the error map.\n",
    "- ‚ùå **Detected inversely** (low usefulness of error maps).\n",
    "\n",
    "![Inverted dark anomaly example](images/inversed_anomaly.png)\n",
    "\n",
    "---\n",
    "\n",
    "**3. Brightness-Only Variations:**  \n",
    "- VAE reconstructed these too well (minor brightness shift), yielding minimal or no significant error.\n",
    "- ‚ùå **Not detectable by VAE**.\n",
    "\n",
    "![Undetected Brightness change](images/brightness_only_anomaly.png)\n",
    "---\n",
    "\n",
    "**4. Texture Disruptions (lines, folds):**  \n",
    "- Clearly visible in error heat maps but resulted in noisy or unusable binary masks.\n",
    "- ‚ùå **Error map too noisy or ambiguous for reliable detection**.\n",
    "\n",
    "![Non usable prediction mask](images/line_not_usable.png)\n",
    "\n",
    "---\n",
    "\n",
    "**5. Small Dot-like Anomalies (Blobs, specks):**  \n",
    "- Clearly highlighted in the error heat map (yellow high-intensity region), but thresholding methods like **Otsu** failed to isolate these small anomalies.\n",
    "- ‚ùå **Difficult to threshold reliably**.\n",
    "\n",
    "![Dot-like anomaly](images/dot_not_usable.png)\n",
    "\n",
    "---\n",
    "\n",
    "### Interpreting Our Observations: Why Did the VAE Struggle?\n",
    "\n",
    "The difficulties we observed weren‚Äôt due to flaws in our implementation but inherent limitations in how VAE-based anomaly detection operates:\n",
    "\n",
    "- **VAEs aim to generalize:** They reconstruct patterns broadly similar to what they saw during training even if these patterns contain subtle anomalies. Thus, anomalies similar to normal patterns were reconstructed too well.\n",
    "- **Pixel-wise losses (MSE, SSIM) are limited:** They heavily penalize brightness shifts or minor noise but do not always correlate strongly with structural anomalies.\n",
    "- **Skip Connections & Attention:** Improved reconstruction quality globally but unfortunately, this also meant some anomalies became easier to reconstruct, resulting in lower error scores for real anomalies.\n",
    "- **Thresholding is a challenging post-processing step:** Even when the anomaly is clearly visible in the error map, simple thresholding (e.g., Otsu) often fails because it doesn‚Äôt consider spatial or structural context.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Thresholding Error Maps Isn‚Äôt Enough\n",
    "\n",
    "As an illustrative example, take the following image:\n",
    "\n",
    "- Error map clearly highlights the anomaly (bright yellow spot).\n",
    "- Yet, thresholding produces an unusable noisy mask.\n",
    "\n",
    "![Clear anomaly but noisy threshold](images/dot_not_usable_2.png)\n",
    "\n",
    "This happens because methods like **Otsu** are global, unsupervised, and lack spatial understanding. They work well with simple or large anomalies, but fail when anomalies are small, subtle, or amidst noisy backgrounds.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb87db",
   "metadata": {},
   "source": [
    "### How VAEs Respond to Different Anomaly Types\n",
    "\n",
    "After extensive experimentation with the AITEX dataset, we noticed that the VAE responded **very differently** to various types of anomalies. Some were detected well, others were reconstructed too well, and some were completely ignored.\n",
    "\n",
    "Let‚Äôs explore why this happens:\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Behavior Summary\n",
    "\n",
    "| **Anomaly Type**            | **Model Response** | **Explanation**                                                                 | **Detection Result** |\n",
    "|-----------------------------|--------------------|----------------------------------------------------------------------------------|-----------------------|\n",
    "| **Bright anomalies** (e.g. white dots, specks) | Reconstructed too dark | VAE has never seen such high intensities ‚Äî it fails to reproduce them correctly | ‚úîÔ∏è Detected well via high error |\n",
    "| **Dark anomalies** (e.g. fissures, holes) | Reconstructed too bright | VAE fills in plausible normal textures; may invert brightness during recon | üîÑ Sometimes inverted / misleading |\n",
    "| **Brightness shifts** (global or regional) | Reconstructed smoothly | Brightness changes are treated as normal variation ‚Äî decoder generalizes well | ‚ùå Undetected (very low error) |\n",
    "| **Texture disruptions** (lines, folds) | Reconstructed with noise | Model can‚Äôt reconstruct unfamiliar structure, but adds noise instead of structure | ‚ö†Ô∏è Error map visible, mask too noisy |\n",
    "| **Small dots or blobs** | Localized in heatmap | Clearly visible in error map, but thresholding (e.g. Otsu) fails due to small size | ‚ö†Ô∏è Good map, but mask extraction fails |\n",
    "\n",
    "---\n",
    "\n",
    "#### Why does this happen?\n",
    "\n",
    "VAEs are trained on **normal data only**. They learn to:\n",
    "- **Compress** input images into a low-dimensional latent space,\n",
    "- And then **reconstruct** them as well as possible.\n",
    "\n",
    "When something **unusual** (an anomaly) appears, the model tries to:\n",
    "- **Explain it away** using what it knows\n",
    "- Or **fails to reconstruct it** and produces high error\n",
    "\n",
    "But:\n",
    "- If the anomaly looks **similar to normal patterns**, the VAE just **reconstructs it as if it's normal**\n",
    "- If the anomaly causes **small, global changes** (like brightness shifts), the decoder **smooths over it**\n",
    "- If the anomaly is **very different**, the VAE **fails** ‚Üí large error ‚Üí detection works\n",
    "\n",
    "---\n",
    "\n",
    "#### Takeaway for Learners\n",
    "\n",
    "> VAEs don‚Äôt \"detect\" anomalies ‚Äî they just try to **rebuild** what they‚Äôre given.\n",
    "> Whether an anomaly gets caught depends entirely on how **strange** it is to the model.\n",
    "\n",
    "This makes VAEs:\n",
    "- Great for **clear outliers** (blobs, holes)\n",
    "- Weak for **subtle shifts** (brightness, small-scale texture drift)\n",
    "- Highly dependent on **post-processing** to extract meaningful masks from error maps\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5285d5",
   "metadata": {},
   "source": [
    "## üîö 3. What Did We Learn from This?\n",
    "\n",
    "This extensive exploration taught us that:\n",
    "\n",
    "- Pure **VAE-based anomaly detection** relies entirely on reconstruction error. It works best when anomalies are distinctly out-of-distribution.\n",
    "- With textured images (like fabrics), anomalies often are subtle or structurally similar to normal patterns, causing reconstruction-based methods alone to struggle.\n",
    "- To move forward, we need models capable of:\n",
    "  - Learning more **semantic or structural features**.\n",
    "  - Better interpreting subtle anomalies.\n",
    "  - Segmenting anomalies from error maps explicitly, rather than relying on global pixel thresholds.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ **Next Steps: Beyond VAE**\n",
    "\n",
    "Given our observations, we naturally moved toward methods like:\n",
    "\n",
    "- **PatchCore:** Leveraging pre-trained features to detect anomalies in feature space.\n",
    "- **DRAEM:** Combining synthetic anomaly generation and supervised segmentation directly, explicitly learning how to identify anomalies.\n",
    "\n",
    "These methods tackle the problems encountered in the VAE experiments head-on, and in our following notebooks, we'll explore what PatchCore and DRAEM can do better where our VAE struggled.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Conclusion for Learners**\n",
    "\n",
    "An important take-home message from this notebook series:\n",
    "\n",
    "- Even experiments that don't yield \"success\" can give invaluable insights.\n",
    "- Understanding why a method **doesn't work** is often the key to choosing methods that **do**.\n",
    "- Being clear about the limitations of reconstruction-based models is crucial when tackling real-world datasets like AITEX.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéì **Final thought:**\n",
    "\n",
    "> ‚ÄúIn anomaly detection, knowing what doesn‚Äôt work (and why) is as valuable as knowing what does. Every 'failure' is just another step toward the right solution.‚Äù\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34ec4a",
   "metadata": {},
   "source": [
    "### Final Reflection: Why VAEs Aren‚Äôt Enough for AITEX\n",
    "\n",
    "Despite multiple architectural improvements like skip connections, attention mechanisms, and gating strategies the core challenge remained:\n",
    "\n",
    "> **Pure VAE-based anomaly detection cannot solve the anomaly segmentation task on AITEX.**\n",
    "\n",
    "This limitation isn‚Äôt a flaw in implementation. It‚Äôs a **design limitation** of the VAE paradigm:\n",
    "\n",
    "- VAEs are built to **reconstruct normal data** ‚Äî but they often **reconstruct anomalies too well**.\n",
    "- Anomalies that look ‚Äúplausible‚Äù to the model are **recreated without high error**, and thus **undetected**.\n",
    "- Subtle anomalies (like brightness shifts or minor texture variations) are **smoothed over**, and never trigger the model‚Äôs alarm.\n",
    "- Postprocessing methods like thresholding or Otsu often fail to extract **meaningful binary masks** from the error map.\n",
    "\n",
    "> In short: **VAEs don't know what an anomaly is. They just try to make sense of what they see.**\n",
    "\n",
    "To go further, we need to:\n",
    "- Move beyond raw reconstruction error,\n",
    "- Introduce **feature-based comparisons**, **learned segmentation**, or **representation learning**,\n",
    "- And **train models that can explicitly distinguish** normal from abnormal ‚Äî not just recreate.\n",
    "\n",
    "---\n",
    "\n",
    "In the next notebook branches, we‚Äôll explore two approaches that do exactly that:\n",
    "\n",
    "- **PatchCore**, which compares feature space distances using pre-trained encoders,\n",
    "- **DRAEM**, which learns to detect anomalies by reconstructing synthetic ones and training a segmentation head.\n",
    "\n",
    "‚û°Ô∏è These methods go beyond the VAE‚Äôs limitations and deliver strong, usable results on the AITEX dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9222226",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 0.8em; text-align: center;\">¬© 2025 Oliver Grau. Educational content for personal use only. See LICENSE.txt for full terms and conditions.</p>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
