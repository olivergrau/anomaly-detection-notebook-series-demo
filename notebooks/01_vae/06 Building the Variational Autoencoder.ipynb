{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1661e3c51e4440e",
   "metadata": {},
   "source": [
    "# **Project: Anomaly Detection for AITEX Dataset**\n",
    "#### Track: VAE\n",
    "## `Notebook 6`: Building the Variational Autoencoder (VAE)\n",
    "**Author**: Oliver Grau \n",
    "\n",
    "**Date**: 27.03.2025  \n",
    "**Version**: 1.0\n",
    "\n",
    "## ðŸ“š Table of Contents\n",
    "\n",
    "- [1. Introduction](#1-introduction)\n",
    "- [2. Overview: Why a VAE?](#2-overview-why-a-vae)\n",
    "- [3. Model Evolution & Design Choices](#3-model-evolution--design-choices)\n",
    "- [4. Custom Loss Functions for Training](#4-custom-loss-functions-for-training)\n",
    "- [5. Instanciating the Model](#5-instanciating-the-model)\n",
    "- [6. Conclusion & Outlook](#5-conclusion--outlook)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "In this notebook, we detail the evolution and architecture of our Variational Autoencoder (VAE) tailored specifically for anomaly detection on the AITEX Fabric Defect Dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Overview: Why a VAE?\n",
    "\n",
    "A **Variational Autoencoder (VAE)** is (for now) suitable for anomaly detection because it learns a probabilistic representation of normal data. Deviations from this learned representation signal anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Model Evolution & Design Choices\n",
    "\n",
    "The AitexVAE model evolved through several iterations, each enhancing its ability to reconstruct fabric images clearly and robustly. As I developed the notebook series I ran through several evolutions of the model and experimented a lot with it. By this experimentation my original model (AitexVAE) evolved and is now in version 8.\n",
    "\n",
    "Hereâ€™s a comprehensive analysis of each model from `AitexVAE` to `AitexVAEv8`:\n",
    "\n",
    "\n",
    "### ðŸŒ± `AitexVAE` â€“ **Baseline Architecture**\n",
    "\n",
    "#### âœ… Architecture\n",
    "- Standard 4-layer CNN encoder (downsampling 256x256 to 16x16).\n",
    "- Fully connected `mu` and `logvar` heads â†’ latent vector.\n",
    "- Decoder:\n",
    "  - Linear â†’ [64, 16, 16] â†’ two transposed convs: 16Ã—16 â†’ 64Ã—64 â†’ 256Ã—256.\n",
    "  - Uses `Sigmoid()` at the end.\n",
    "\n",
    "#### ðŸŽ¯ Purpose\n",
    "- Establishes a minimal working baseline.\n",
    "- Strong downsampling but **shallow decoder** â†’ limited recon power.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§° `AitexVAEv2` â€“ **Configurable Channels**\n",
    "\n",
    "#### âœ… What's New\n",
    "- You can define:\n",
    "  - `encoder_channels` (e.g., [32, 64, 128, 256])\n",
    "  - `decoder_channels` (e.g., [64, 32, 1])\n",
    "- Adds flexibility for experimentation.\n",
    "- Transposed convolutions still used in decoder.\n",
    "\n",
    "#### ðŸŽ¯ Purpose\n",
    "- Tune network capacity and symmetry.\n",
    "- Still no bottleneck/BatchNorm or attention.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§± `AitexVAEv3` â€“ **Fixed but Stronger Decoder**\n",
    "\n",
    "#### âœ… What's New\n",
    "- Encoder and decoder are hardcoded like v1, but with:\n",
    "  - More consistent depth: encoder ends with 256-channels\n",
    "  - Decoder starts from `[64, 16, 16]` (like v1), upsampled in 2 big steps\n",
    "\n",
    "#### ðŸŽ¯ Purpose\n",
    "- Simple fixed-structure VAE.\n",
    "- Control experiment for future improvements.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”„ `AitexVAEv4` â€“ **Improved Decoder and Bottleneck**\n",
    "\n",
    "#### âœ… What's New\n",
    "- Introduces:\n",
    "  - **BatchNorm1d** in bottleneck.\n",
    "  - A **fully connected intermediate layer** before `mu`/`logvar`.\n",
    "  - Optional **SEBlock** (attention) before decoding.\n",
    "- Decoder starts at `[256, 16, 16]` and upsamples in 4 steps.\n",
    "\n",
    "#### ðŸŽ¯ Purpose\n",
    "- Normalize latent distributions.\n",
    "- Strengthen decoder.\n",
    "- Add optional attention to guide decoding.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”— `AitexVAEv5` â€“ **Skip Connections (Additive)**\n",
    "\n",
    "#### âœ… What's New\n",
    "- First model to use **additive skip connections** from encoder to decoder.\n",
    "- Encoder stores feature maps from each conv layer.\n",
    "- Decoder adds skip features after each upsampling stage.\n",
    "\n",
    "#### ðŸŽ¯ Purpose\n",
    "- Improve reconstructions by **reusing spatial context**.\n",
    "- Add spatial detail from encoder to decoder.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”—âž• `AitexVAEv6` â€“ **Skip Connections (Concat)**\n",
    "\n",
    "#### âœ… What's New\n",
    "- Instead of adding, uses **concatenation** for skip connections.\n",
    "- Each concat is followed by a **1Ã—1 conv** to reduce channels.\n",
    "- More flexible than additive: lets the model learn fusion.\n",
    "\n",
    "#### ðŸŽ¯ Purpose\n",
    "- Empower the decoder to **learn how much to use from encoder**.\n",
    "- Improve gradient flow and spatial recovery.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸšªðŸ”’ `AitexVAEv8` â€“ **Gated Skip Connections (ChannelGate)**\n",
    "\n",
    "#### âœ… What's New\n",
    "- Replaces concat with **learnable gates per channel** (ChannelGate).\n",
    "- Gate = sigmoid(MLP(average pooled enc_feat)) â†’ weight per channel.\n",
    "- Each decoder feature map gets **modulated encoder features**, added in.\n",
    "\n",
    "#### ðŸŽ¯ Purpose\n",
    "- Let the model **learn how much encoder info to pass at each stage**.\n",
    "- Greatly improves control and reduces noisy skip information.\n",
    "- Cleaner gradients and better reconstruction control.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ“ Overall Evolution Summary\n",
    "\n",
    "| Version    | Key Idea                        | Strengths                                 |\n",
    "|------------|----------------------------------|--------------------------------------------|\n",
    "| `AitexVAE` | Basic baseline                  | Easy to train, limited decoder             |\n",
    "| `v2`       | Configurable channel structure  | Good for hyperparameter tuning             |\n",
    "| `v3`       | Stronger decoder                | More stable reconstruction                 |\n",
    "| `v4`       | Bottleneck + Attention          | Normalize latent + SE refinement           |\n",
    "| `v5`       | Additive skip connections       | Preserves spatial features                 |\n",
    "| `v6`       | Concat skip connections         | Learnable fusion, flexible                 |\n",
    "| `v8`       | **Gated** skip connections      | Best control over encoder info reuse       |\n",
    "\n",
    "You've just explored a carefully crafted **evolutionary series of VAE architectures**, developed through an iterative process of **training â†’ evaluation â†’ architectural refinement â†’ retraining**. Each version introduces new ideas and structural changes aimed at better addressing the unique challenges posed by the AITEX fabric dataset.\n",
    "\n",
    "This progression ultimately led us to version **`AitexVAEv8`**, which incorporates gated skip connections for more controlled feature reuse. This is our most advanced and expressive VAE so far.\n",
    "\n",
    "As a learner, you're free to:\n",
    "- âœ… Try out any of the intermediate versions to better understand how each architectural change affects performance, or\n",
    "- ðŸš€ Jump straight to the conclusions in **`08_Why the VAE Struggles with AITEX Anomaly Detection.ipynb`**, where we summarize key insights from this VAE branch and explain why this approach, despite its strengths, faces fundamental limitations on the AITEX dataset.\n",
    "\n",
    "The choice is yours! Whether to dive deep into each version or continue forward in your anomaly detection journey. If you want to dive deep into the journey then start with the notebook **`07_Training the model.ipynb`**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Custom Loss Functions for Training\n",
    "\n",
    "Our VAEs were trained using custom loss functions, blending spatial and frequency-domain reconstruction metrics with KL divergence to ensure high-fidelity reconstructions and meaningful latent representations.\n",
    "\n",
    "### Key Loss Functions:\n",
    "- **`vae_loss`**: Classic VAE loss (MSE + KL divergence).\n",
    "- **`frequency_vae_loss`**: Loss computed on FFT magnitudes of images (captures textural details).\n",
    "- **`log_scaled_frequency_vae_loss`**: Uses log-scaled FFT magnitudes for better handling varying signal strengths.\n",
    "- **`hybrid_vae_loss`**: Combines spatial MSE and frequency-domain losses.\n",
    "- **`hybrid_spatial_vae_loss`**: Advanced hybrid loss integrating FFT magnitude, MSE, and Structural Similarity Index (SSIM).\n",
    "\n",
    "This hybrid approach significantly improved anomaly detection sensitivity and reconstruction quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e05ea300f75b4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Instanciate the Model\n",
    "\n",
    "Let's set up the model and print out the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765b7b6dc6efa053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T17:20:28.580323Z",
     "start_time": "2025-03-25T17:20:26.422339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AitexVAEv8(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (drop1): Dropout2d(p=0.1, inplace=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (drop2): Dropout2d(p=0.1, inplace=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (drop3): Dropout2d(p=0.1, inplace=False)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (drop4): Dropout2d(p=0.1, inplace=False)\n",
      "  (fc_intermediate): Linear(in_features=65536, out_features=1024, bias=True)\n",
      "  (bn_intermediate): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc_mu): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc_logvar): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc_dec): Linear(in_features=128, out_features=65536, bias=True)\n",
      "  (seblock): SEBlock(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (up1): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (up2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (up3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (up4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (gate4): ChannelGate(\n",
      "    (fc): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (gate3): ChannelGate(\n",
      "    (fc): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (gate2): ChannelGate(\n",
      "    (fc): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (gate1): ChannelGate(\n",
      "    (fc): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from codebase.models.vae.aitex_vae import AitexVAEv2, AitexVAE, AitexVAEv3, AitexVAEv8\n",
    "from torch import optim\n",
    "\n",
    "# Instantiate the model\n",
    "model = AitexVAEv8(\n",
    "    in_channels=1, latent_dim=128, dropout_p=0.1, use_attention=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) # , weight_decay=1e-6)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dcfb7edfa5c311",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ðŸ”š Conclusion & Outlook\n",
    "\n",
    "With the robust VAE architecture finalized and powerful loss functions defined, our next steps include:\n",
    "- **Training and tuning** the AitexVAE model on fabric patches\n",
    "- **Evaluating reconstruction quality** and anomaly detection performance\n",
    "- **Optimizing** hyperparameters like latent dimensions, KL divergence weighting, and dropout rates for maximum anomaly detection accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbde2d0",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 0.8em; text-align: center;\">Â© 2025 Oliver Grau. Educational content for personal use only. See LICENSE.txt for full terms and conditions.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
