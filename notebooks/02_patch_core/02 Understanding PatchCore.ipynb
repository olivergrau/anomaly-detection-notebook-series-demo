{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb1dc4d4c30bbdd",
   "metadata": {},
   "source": [
    "# **Project: Anomaly Detection for AITEX Dataset**\n",
    "#### Track: PatchCore\n",
    "## `Notebook 2`: Understanding PatchCore\n",
    "**Author**: Oliver Grau \n",
    "\n",
    "**Date**: 27.03.2025  \n",
    "**Version**: 1.0\n",
    "\n",
    "## üìö Table of Contents\n",
    "\n",
    "- [1. Motivation: A New Perspective on Anomaly Detection](#1-motivation-a-new-perspective-on-anomaly-detection)\n",
    "- [2. PatchCore vs. Autoencoder-based Detection](#2-patchcore-vs-autoencoder-based-detection)\n",
    "- [3. The PatchCore Pipeline](#3-the-patchcore-pipeline)\n",
    "- [4. Mathematical Formulation](#4-mathematical-formulation)\n",
    "- [5. Key Concepts in Detail](#5-key-concepts-in-detail)\n",
    "- [6. Strengths and Limitations](#6-strengths-and-limitations)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Motivation: A New Perspective on Anomaly Detection\n",
    "\n",
    "Reconstruction-based anomaly detection models, such as Autoencoders or VAEs, attempt to learn a compressed representation of the input and detect anomalies via reconstruction error. However, they often fail to detect subtle or small anomalies and may generalize too well. PatchCore addresses this by entirely abandoning the need for reconstruction.\n",
    "\n",
    "Instead of reconstructing input images, PatchCore detects anomalies by comparing localized image features with known normal features stored in a memory bank. The core idea is simple: \"if something looks unlike anything we've seen during training, it's likely anomalous.\"\n",
    "\n",
    "---\n",
    "\n",
    "## 2. PatchCore vs. Autoencoder-based Detection\n",
    "\n",
    "| üîÑ Aspect                      | ü§ñ Autoencoder/VAE               | üß† PatchCore                              |\n",
    "|-------------------------------|----------------------------------|-------------------------------------------|\n",
    "| Learning type                 | Unsupervised, generative         | Unsupervised, discriminative              |\n",
    "| Training phase                | Required (end-to-end)            | None (feature extractor is frozen)        |\n",
    "| Representation                | Latent vector (z)                | Patch embeddings from pretrained CNN     |\n",
    "| Anomaly signal                | High reconstruction error        | Large distance to normal patch features   |\n",
    "| Assumption                    | Anomalies can't be reconstructed | Anomalies are different in feature space  |\n",
    "\n",
    "PatchCore is more robust because it uses pretrained CNNs (e.g., ResNet) trained on large-scale datasets like ImageNet. These networks have learned rich, general features that capture shape, texture, and structure without being **tuned** to the target anomaly dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. The PatchCore Pipeline\n",
    "\n",
    "1. **Feature Extraction**:\n",
    "   - Use a pretrained CNN to extract intermediate feature maps from normal training images.\n",
    "\n",
    "2. **Unfolding**:\n",
    "   - Break the feature maps into patch vectors by flattening the spatial dimensions.\n",
    "\n",
    "3. **CoreSet Sampling (optional)**:\n",
    "   - Select a representative subset of patch features to build a memory bank.\n",
    "\n",
    "4. **Inference**:\n",
    "   - For each test image, extract patch features and compute their distances to the closest features in the memory bank.\n",
    "\n",
    "5. **Scoring**:\n",
    "   - The anomaly score for a patch is the distance to its nearest neighbor in the memory bank.\n",
    "   - Image-level anomaly scores are computed by aggregating (e.g., max or mean) patch-level scores.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Mathematical Formulation\n",
    "\n",
    "Let $ x \\in \\mathbb{R}^{H \\times W} $ be an input image, and $ f(x) \\in \\mathbb{R}^{C \\times H' \\times W'} $ be the feature map extracted from a pretrained CNN.\n",
    "\n",
    "### Unfold to Patches:\n",
    "\n",
    "We reshape the feature map to obtain patch vectors:\n",
    "$$\n",
    "P = \\text{Unfold}(f(x)) \\in \\mathbb{R}^{N \\times C}, \\quad \\text{where } N = H' \\cdot W'\n",
    "$$\n",
    "\n",
    "### Memory Bank:\n",
    "\n",
    "Constructed from patch vectors $ P_1, P_2, ..., P_M $ extracted from M training images (only normal samples):\n",
    "$$\n",
    "\\mathcal{M} = \\bigcup_{i=1}^M P_i\n",
    "$$\n",
    "\n",
    "### Anomaly Score:\n",
    "\n",
    "For each patch vector $ p \\in P $, compute its nearest-neighbor distance:\n",
    "$$\n",
    "d(p) = \\min_{m \\in \\mathcal{M}} \\| p - m \\|_2\n",
    "$$\n",
    "\n",
    "The image-level score can be:\n",
    "$$\n",
    "s(x) = \\max_{p \\in P} d(p) \\quad \\text{or} \\quad s(x) = \\frac{1}{N} \\sum_{p \\in P} d(p)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Key Concepts in Detail\n",
    "\n",
    "### Memory Bank\n",
    "A memory bank $ \\mathcal{M} $ stores the patch-level feature vectors extracted from normal training images. It serves as the reference distribution of normality.\n",
    "\n",
    "### Feature Unfolding\n",
    "Instead of summarizing an entire image into one embedding, we preserve spatial structure by extracting patch-wise embeddings from intermediate CNN layers.\n",
    "\n",
    "### Distance Metric\n",
    "PatchCore uses the Euclidean distance $ \\| p - m \\|_2 $ to determine similarity. Other distance metrics or approximate nearest neighbor (ANN) search can be used to scale to larger datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Strengths and Limitations\n",
    "\n",
    "### ‚úÖ Strengths:\n",
    "- No training required (only feature extraction)\n",
    "- Strong generalization to unseen anomalies\n",
    "- Local, patch-wise scoring enables fine-grained anomaly localization\n",
    "- Works well even with few training images\n",
    "\n",
    "### ‚ö†Ô∏è Limitations:\n",
    "- Memory Bank can become large without CoreSet sampling\n",
    "- No end-to-end learning or fine-tuning possible\n",
    "- Patch-wise independence may lead to false positives in noisy textures\n",
    "\n",
    "PatchCore trades off learnable complexity for robust generalization. For many industrial tasks, this is exactly the right balance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8d5f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"border-left: 4px solid #007acc; padding: 0.8em; background-color: #f0f8ff; margin-bottom: 1em;\">\n",
    "  <strong>üí° Reader Question:</strong> <br><br>In case you are confused what the Patch in <b>PatchCore</b> means and how it differentiate from the patches we created from the AITEX dataset - here is a clarification of both domain terms: Patch AITEX and Patch from <b>PatchCore</b>.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "# What Does ‚ÄúPatch‚Äù Mean in PatchCore?\n",
    "\n",
    "The name **PatchCore** stems from the core concept of operating on **small spatial regions (patches)** extracted from full-sized feature maps.\n",
    "\n",
    "## In PatchCore:\n",
    "\n",
    "- A ‚Äúpatch‚Äù refers to a **small feature vector** extracted from a **feature map** produced by a pretrained backbone (e.g., ResNet34 or DenseNet).\n",
    "- These feature maps come from an input image of shape `[B, C, H, W]` and typically have **downsampled spatial resolution** (e.g., 32√ó32).\n",
    "- PatchCore extracts all **spatial positions** from this feature map:\n",
    "  \n",
    "  **Example:**\n",
    "  ```\n",
    "  Feature map shape: [B, C, H=32, W=32] ‚Üí 1024 patches per image\n",
    "  Each patch: vector of C dimensions (e.g., 192 or 448)\n",
    "  ```\n",
    "\n",
    "- These extracted patches become the **units of memory** in a FAISS (this is explained in later notebooks) index. During inference, new test patches are compared against the stored normal patches to detect anomalies based on distance.\n",
    "\n",
    "> So in PatchCore, a *patch* is not a cut-out piece of the image, but a **positionally extracted feature embedding** from a CNN.\n",
    "\n",
    "---\n",
    "\n",
    "# How Does This Differ from Your AITEX Patches?\n",
    "\n",
    "In your AITEX data preparation:\n",
    "\n",
    "- You pre-split each **4096√ó256** fabric strip into **explicit, fixed-size image patches**, typically **256√ó256 pixels**, using a sliding window or tiling.\n",
    "- These are true **image-level crops**, saved to disk or loaded into memory.\n",
    "- They are then individually passed through a model or fed into PatchCore‚Äôs feature extractor.\n",
    "\n",
    "## ‚ö†Ô∏è Important Distinction:\n",
    "\n",
    "| Aspect                   | AITEX Patches                         | PatchCore Patches                     |\n",
    "|--------------------------|---------------------------------------|----------------------------------------|\n",
    "| Type                     | Image crops (e.g., 256√ó256)           | Feature vectors from CNN outputs       |\n",
    "| Purpose                  | Preprocessing granularity             | Anomaly detection granularity          |\n",
    "| Memory Bank Content      | N/A (full image)                      | CNN patch embeddings                   |\n",
    "| Unit of Similarity Check | Whole patch vs. anomaly-free sample  | Patch-level vector vs. memory vectors  |\n",
    "\n",
    "---\n",
    "\n",
    "# ü§î Why Is It Called ‚ÄúPatchCore‚Äù?\n",
    "\n",
    "The name comes from:\n",
    "- **Patch-level representation**: operating on small parts of an image (via CNN feature maps)\n",
    "- **Core-set sampling**: a selection algorithm used to reduce the size of the memory bank while retaining coverage\n",
    "\n",
    "So PatchCore = Patch-wise Comparison + Core-set Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4825a655",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 0.8em; text-align: center;\">¬© 2025 Oliver Grau. Educational content for personal use only. See LICENSE.txt for full terms and conditions.</p>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
